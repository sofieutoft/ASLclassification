{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('CNN_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONTINUOUS IMAGE\n",
    "def preprocess_image(image):\n",
    "    resized_image = cv2.resize(image, (28, 28))\n",
    "    grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    normalized_image = grayscale_image / 255.0\n",
    "    \n",
    "    # Save the processed grayscale image\n",
    "    cv2.imwrite('processed_frame.jpg', normalized_image * 255)\n",
    "    \n",
    "    reshaped_image = normalized_image.reshape(1, 28, 28, 1)\n",
    "    return reshaped_image\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Set the frame width to 640 pixels\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # Set the frame height to 480 pixels\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame\")\n",
    "        break\n",
    "    \n",
    "    # Resize the frame to a smaller size\n",
    "    resized_frame = cv2.resize(frame, (320, 240))\n",
    "    \n",
    "    processed_frame = preprocess_image(resized_frame)\n",
    "    \n",
    "    prediction = model.predict(processed_frame)\n",
    "    predicted_letter = chr(prediction.argmax() + 65)\n",
    "    \n",
    "    # Display prediction\n",
    "    cv2.putText(frame, predicted_letter, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('ASL Prediction', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CAPTURE IMAGE\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def preprocess_image(image):\n",
    "    resized_image = cv2.resize(image, (28, 28))\n",
    "    grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    normalized_image = grayscale_image / 255.0\n",
    "    reshaped_image = normalized_image.reshape(1, 28, 28, 1)\n",
    "    return reshaped_image\n",
    "\n",
    "def take_photo_and_preprocess(filename='photo.jpg', quality=0.8):\n",
    "    js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "        const div = document.createElement('div');\n",
    "        const capture = document.createElement('button');\n",
    "        capture.textContent = 'Capture';\n",
    "        div.appendChild(capture);\n",
    "        const video = document.createElement('video');\n",
    "        video.style.display = 'block';\n",
    "        const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "        document.body.appendChild(div);\n",
    "        div.appendChild(video);\n",
    "        video.srcObject = stream;\n",
    "        await video.play();\n",
    "\n",
    "        // Resize the output to fit the video element.\n",
    "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "        // Wait for Capture to be clicked.\n",
    "        await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "        const canvas = document.createElement('canvas');\n",
    "        canvas.width = video.videoWidth;\n",
    "        canvas.height = video.videoHeight;\n",
    "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "        stream.getVideoTracks()[0].stop();\n",
    "        div.remove();\n",
    "        return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "    display(js)\n",
    "    data = eval_js('takePhoto({})'.format(quality))\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "    image = cv2.imdecode(np.frombuffer(binary, np.uint8), -1)\n",
    "    \n",
    "    processed_frame = preprocess_image(image)\n",
    "    \n",
    "    return processed_frame\n",
    "\n",
    "# Capture images and make predictions\n",
    "for i in range(5):  # Capturing 5 images\n",
    "    print(f\"Capturing image {i}...\")\n",
    "    processed_frame = take_photo_and_preprocess()\n",
    "    \n",
    "    prediction = model.predict(processed_frame)\n",
    "    predicted_letter = chr(prediction.argmax() + 65)\n",
    "    print(f\"Predicted letter for image {i}: {predicted_letter}\")\n",
    "    \n",
    "    print(\"Image capture complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HAND DETECTION\n",
    "# Load the Haar cascade hand detection model\n",
    "hand_cascade = cv2.CascadeClassifier('hand.xml')\n",
    "\n",
    "def preprocess_image(image):\n",
    "    resized_image = cv2.resize(image, (28, 28))\n",
    "    grayscale_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "    normalized_image = grayscale_image / 255.0\n",
    "    reshaped_image = normalized_image.reshape(1, 28, 28, 1)\n",
    "    return reshaped_image\n",
    "\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_AVFOUNDATION)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # Set the frame width to 640 pixels\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)  # Set the frame height to 480 pixels\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame\")\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect hands in the frame\n",
    "    hands = hand_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    # Draw rectangles around the detected hands\n",
    "    for (x, y, w, h) in hands:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        \n",
    "        # Adjust the region of interest (ROI) to focus on the hand\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        \n",
    "        # Resize the ROI to the desired input size for the model\n",
    "        resized_roi = cv2.resize(roi, (28, 28))\n",
    "        \n",
    "        # Preprocess the resized ROI\n",
    "        processed_frame = preprocess_image(resized_roi)\n",
    "        \n",
    "        # Make prediction using the model\n",
    "        prediction = model.predict(processed_frame)\n",
    "        predicted_letter = chr(prediction.argmax() + 65)\n",
    "        \n",
    "        # Display prediction\n",
    "        cv2.putText(frame, predicted_letter, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow('ASL Prediction', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "_, frame = cap.read()\n",
    "\n",
    "h, w, c = frame.shape\n",
    "\n",
    "img_counter = 0\n",
    "analysisframe = ''\n",
    "letterpred = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        analysisframe = frame\n",
    "        showframe = analysisframe\n",
    "        cv2.imshow(\"Frame\", showframe)\n",
    "        framergbanalysis = cv2.cvtColor(analysisframe, cv2.COLOR_BGR2RGB)\n",
    "        resultanalysis = hands.process(framergbanalysis)\n",
    "        hand_landmarksanalysis = resultanalysis.multi_hand_landmarks\n",
    "        if hand_landmarksanalysis:\n",
    "            for handLMsanalysis in hand_landmarksanalysis:\n",
    "                x_max = 0\n",
    "                y_max = 0\n",
    "                x_min = w\n",
    "                y_min = h\n",
    "                for lmanalysis in handLMsanalysis.landmark:\n",
    "                    x, y = int(lmanalysis.x * w), int(lmanalysis.y * h)\n",
    "                    if x > x_max:\n",
    "                        x_max = x\n",
    "                    if x < x_min:\n",
    "                        x_min = x\n",
    "                    if y > y_max:\n",
    "                        y_max = y\n",
    "                    if y < y_min:\n",
    "                        y_min = y\n",
    "                y_min -= 20\n",
    "                y_max += 20\n",
    "                x_min -= 20\n",
    "                x_max += 20 \n",
    "\n",
    "        analysisframe = cv2.cvtColor(analysisframe, cv2.COLOR_BGR2GRAY)\n",
    "        analysisframe = analysisframe[y_min:y_max, x_min:x_max]\n",
    "        analysisframe = cv2.resize(analysisframe,(28,28))\n",
    "\n",
    "\n",
    "        nlist = []\n",
    "        rows,cols = analysisframe.shape\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                k = analysisframe[i,j]\n",
    "                nlist.append(k)\n",
    "        \n",
    "        datan = pd.DataFrame(nlist).T\n",
    "        colname = []\n",
    "        for val in range(784):\n",
    "            colname.append(val)\n",
    "        datan.columns = colname\n",
    "\n",
    "        pixeldata = datan.values\n",
    "        pixeldata = pixeldata / 255\n",
    "        pixeldata = pixeldata.reshape(-1,28,28,1)\n",
    "        prediction = model.predict(pixeldata)\n",
    "        predarray = np.array(prediction[0])\n",
    "        letter_prediction_dict = {letterpred[i]: predarray[i] for i in range(len(letterpred))}\n",
    "        predarrayordered = sorted(predarray, reverse=True)\n",
    "        high1 = predarrayordered[0]\n",
    "        high2 = predarrayordered[1]\n",
    "        high3 = predarrayordered[2]\n",
    "        for key,value in letter_prediction_dict.items():\n",
    "            if value==high1:\n",
    "                print(\"Predicted Character 1: \", key)\n",
    "                print('Confidence 1: ', 100*value)\n",
    "            elif value==high2:\n",
    "                print(\"Predicted Character 2: \", key)\n",
    "                print('Confidence 2: ', 100*value)\n",
    "            elif value==high3:\n",
    "                print(\"Predicted Character 3: \", key)\n",
    "                print('Confidence 3: ', 100*value)\n",
    "        time.sleep(5)\n",
    "\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(framergb)\n",
    "    hand_landmarks = result.multi_hand_landmarks\n",
    "    if hand_landmarks:\n",
    "        for handLMs in hand_landmarks:\n",
    "            x_max = 0\n",
    "            y_max = 0\n",
    "            x_min = w\n",
    "            y_min = h\n",
    "            for lm in handLMs.landmark:\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "            y_min -= 20\n",
    "            y_max += 20\n",
    "            x_min -= 20\n",
    "            x_max += 20\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
